{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mlp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\aadarsh\\\\Desktop\\\\new_6_month_internship\\\\FaceMaskDetection-master'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3067 images belonging to 2 classes.\n",
      "Found 766 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    "    )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory='dataset',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        subset ='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        directory='dataset',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        subset='validation')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr,l):\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(20,20))\n",
    "    #print(axes)\n",
    "    axes = axes.flatten()\n",
    "    print(axes)\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.xlabel(l)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, labels = next(validation_generator)# The next function returns a batch from the dataset.\n",
    "                                                      # The return value of next function is in form of (x_train, y_train)\n",
    "                                                      # where x_train is training features and y_train, its labels.\n",
    "                                                      # Discard the labels to only visualize the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6e19eaccfb00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_training_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m   \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_training_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m   \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "  plt.subplot(5,5,i%25+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(sample_training_images[i])\n",
    "  x = image.img_to_array(sample_training_images[i])\n",
    "  x = np.expand_dims(x,axis = 0)\n",
    "  c = model.predict_classes(x)\n",
    "  s=\"p: {} a: {}\".format(c,labels[i])\n",
    "  plt.xlabel(s)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',#optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import tensorflow\n",
    "import tensorflow.keras\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "31/95 [========>.....................] - ETA: 2:32 - loss: 0.6210 - accuracy: 0.6683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/95 [==========================>...] - ETA: 17s - loss: 0.4577 - accuracy: 0.7906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 226s 2s/step - loss: 0.4492 - accuracy: 0.7964 - val_loss: 0.2220 - val_accuracy: 0.9212\n",
      "Epoch 2/10\n",
      "23/95 [======>.......................] - ETA: 2:11 - loss: 0.3535 - accuracy: 0.8560"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/95 [================>.............] - ETA: 1:17 - loss: 0.3329 - accuracy: 0.8644"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 220s 2s/step - loss: 0.3246 - accuracy: 0.8702 - val_loss: 0.2724 - val_accuracy: 0.8927\n",
      "Epoch 3/10\n",
      "47/95 [=============>................] - ETA: 1:56 - loss: 0.3060 - accuracy: 0.8850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/95 [===============>..............] - ETA: 1:47 - loss: 0.3101 - accuracy: 0.8811"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 257s 3s/step - loss: 0.3022 - accuracy: 0.8843 - val_loss: 0.2332 - val_accuracy: 0.9076\n",
      "Epoch 4/10\n",
      "20/95 [=====>........................] - ETA: 3:09 - loss: 0.2916 - accuracy: 0.8906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/95 [=======>......................] - ETA: 2:36 - loss: 0.2800 - accuracy: 0.8924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 194s 2s/step - loss: 0.2695 - accuracy: 0.8988 - val_loss: 0.2770 - val_accuracy: 0.9022\n",
      "Epoch 5/10\n",
      "27/95 [=======>......................] - ETA: 1:48 - loss: 0.2513 - accuracy: 0.8970"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/95 [=================>............] - ETA: 1:07 - loss: 0.2567 - accuracy: 0.8936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 180s 2s/step - loss: 0.2429 - accuracy: 0.9005 - val_loss: 0.1515 - val_accuracy: 0.9524\n",
      "Epoch 6/10\n",
      "53/95 [===============>..............] - ETA: 1:19 - loss: 0.2716 - accuracy: 0.8974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/95 [========================>.....] - ETA: 26s - loss: 0.2677 - accuracy: 0.9010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 182s 2s/step - loss: 0.2666 - accuracy: 0.9002 - val_loss: 0.2031 - val_accuracy: 0.9253\n",
      "Epoch 7/10\n",
      "11/95 [==>...........................] - ETA: 2:19 - loss: 0.2540 - accuracy: 0.9205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/95 [=====================>........] - ETA: 42s - loss: 0.2521 - accuracy: 0.9094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 182s 2s/step - loss: 0.2417 - accuracy: 0.9105 - val_loss: 0.1697 - val_accuracy: 0.9497\n",
      "Epoch 8/10\n",
      "20/95 [=====>........................] - ETA: 2:24 - loss: 0.2360 - accuracy: 0.9095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/95 [========>.....................] - ETA: 2:03 - loss: 0.2377 - accuracy: 0.9155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 189s 2s/step - loss: 0.2348 - accuracy: 0.9139 - val_loss: 0.1767 - val_accuracy: 0.9361\n",
      "Epoch 9/10\n",
      "27/95 [=======>......................] - ETA: 1:49 - loss: 0.3051 - accuracy: 0.8854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/95 [======================>.......] - ETA: 36s - loss: 0.2679 - accuracy: 0.9007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 169s 2s/step - loss: 0.2514 - accuracy: 0.9058 - val_loss: 0.1489 - val_accuracy: 0.9497\n",
      "Epoch 10/10\n",
      "49/95 [==============>...............] - ETA: 1:12 - loss: 0.2221 - accuracy: 0.9130"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/95 [====================>.........] - ETA: 43s - loss: 0.2388 - accuracy: 0.9056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadarsh\\anaconda3\\lib\\site-packages\\PIL\\Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 163s 2s/step - loss: 0.2322 - accuracy: 0.9107 - val_loss: 0.1625 - val_accuracy: 0.9402\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples // batch_size,\n",
    "      epochs=10,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"freshface.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"face_mask2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "img = image.load_img(\"nomask2.jpg\",target_size= (150,150))\n",
    "import numpy as np\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis = 0)\n",
    "classes = model.predict_classes(x)\n",
    "\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#model = load_model('model.h5')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "img = cv2.imread('nomask1.jpeg')\n",
    "img = cv2.resize(img,(150,150))\n",
    "img = np.reshape(img,[1,150,150,3])\n",
    "\n",
    "image = tf.image.decode_jpeg(img)\n",
    "#image = tf.cast(image, tf.int32)\n",
    "classes = model.predict_classes(image)\n",
    "\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "source=cv2.VideoCapture(0)\n",
    "\n",
    "labels_dict={0:'MASK',1:'NO MASK'}\n",
    "color_dict={0:(0,255,0),1:(0,0,255)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "\n",
    "    ret,img=source.read()\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_clsfr.detectMultiScale(gray,1.3,5)  \n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "    \n",
    "        face_img=img[y:y+w,x:x+w]\n",
    "        resized=cv2.resize(face_img,(150,150))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
    "        result=model.predict_classes(reshaped)\n",
    "        print(result)\n",
    "\n",
    "        #label=np.argmax(result,axis=1)[0]\n",
    "        print(result[0][0])\n",
    "      \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[result[0][0]],2)\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[result[0][0]],-1)\n",
    "        cv2.putText(img, labels_dict[result[0][0]], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow('LIVE',img)\n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    "    if(key==27):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "s=np.arange(12).reshape(1,2,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
